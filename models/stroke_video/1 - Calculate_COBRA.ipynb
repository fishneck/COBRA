{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn.metrics as metrics\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process model output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_COBRA(HC_dir,HAR_dir):\n",
    "    acts = ['brushing','combing','deodorant','drinking','facewash','feeding','glasses','shelf','RTT']\n",
    "    ##############################\n",
    "    ### model output - healthy ###\n",
    "    ##############################\n",
    "    confidence_hc = {}\n",
    "    confidence_hc['sub'] = []\n",
    "    confidence_hc['act'] = []\n",
    "    confidence_hc['rep'] = []\n",
    "    confidence_hc['prob'] = []\n",
    "    confidence_hc['label'] = []\n",
    "    for f in os.listdir(HC_dir):\n",
    "        if 'label' not in f:\n",
    "            sub = int(f.split('000')[1].split('_')[0])\n",
    "            for a in acts:\n",
    "                if a=='deodorant':\n",
    "                    if 'deodrant' in f or 'deodorant' in f:\n",
    "                        act=a\n",
    "                elif a=='facewash':\n",
    "                    if 'face' in f:\n",
    "                        act=a\n",
    "                else:\n",
    "                    if a in f:\n",
    "                        act=a                \n",
    "            rep = f.split('.n')[0][-3:]\n",
    "            prob = np.load(HC_dir+'/'+f)\n",
    "            label = np.load(HC_dir+'/'+f.replace('.npy','_label.npy'))\n",
    "            confidence_hc['sub'].append(sub)\n",
    "            confidence_hc['act'].append(act)\n",
    "            confidence_hc['rep'].append(rep)\n",
    "            confidence_hc['prob'].append(prob)\n",
    "            confidence_hc['label'].append(label)\n",
    "\n",
    "    HC_df = pd.DataFrame(confidence_hc)\n",
    "    HC_df['motion_prob'] = HC_df[['prob','label']].apply(lambda x: np.mean(x[0].max(axis=1)[x[1]<3]),axis=1)\n",
    "    HC_df['non_motion_prob'] = HC_df[['prob','label']].apply(lambda x: np.mean(x[0].max(axis=1)[x[1]>2]),axis=1)\n",
    "    HC_df['all_prob'] = HC_df[['prob','label']].apply(lambda x: np.mean(x[0].max(axis=1)),axis=1)\n",
    "    \n",
    "    #############################\n",
    "    ### model output - stroke ###\n",
    "    #############################\n",
    "    confidence_har = {}\n",
    "    confidence_har['sub'] = []\n",
    "    confidence_har['act'] = []\n",
    "    confidence_har['rep'] = []\n",
    "    confidence_har['prob'] = []\n",
    "    confidence_har['label'] = []\n",
    "    for f in os.listdir(HAR_dir):\n",
    "        if 'label' not in f:\n",
    "            sub = int(f.split('000')[1].split('_')[0])\n",
    "            for a in acts:\n",
    "                if a=='deodorant':\n",
    "                    if 'deodrant' in f or 'deodorant' in f:\n",
    "                        act=a\n",
    "                elif a=='facewash':\n",
    "                    if 'face' in f:\n",
    "                        act=a\n",
    "                else:\n",
    "                    if a in f:\n",
    "                        act=a                \n",
    "            rep = f.split('.n')[0][-3:]\n",
    "            prob = np.load(HAR_dir+'/'+f)\n",
    "            label = np.load(HAR_dir+'/'+f.replace('.npy','_label.npy'))\n",
    "            confidence_har['sub'].append(sub)\n",
    "            confidence_har['act'].append(act)\n",
    "            confidence_har['rep'].append(rep)\n",
    "            confidence_har['prob'].append(prob)\n",
    "            confidence_har['label'].append(label)\n",
    "\n",
    "    HAR_df = pd.DataFrame(confidence_har)\n",
    "    HAR_df['motion_prob'] = HAR_df[['prob','label']].apply(lambda x: np.mean(x[0].max(axis=1)[x[0].argmax(axis=1)<3]),axis=1)\n",
    "    HAR_df['non_motion_prob'] = HAR_df[['prob','label']].apply(lambda x: np.mean(x[0].max(axis=1)[x[0].argmax(axis=1)>2]),axis=1)\n",
    "    HAR_df['all_prob'] = HAR_df[['prob','label']].apply(lambda x: np.mean(x[0].max(axis=1)),axis=1)\n",
    "\n",
    "    return HC_df, HAR_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate COBRA acore for all video outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "HC_df = None\n",
    "HAR_df = None\n",
    "HC_blurred_df = None\n",
    "HAR_blurred_df = None\n",
    "\n",
    "\n",
    "n_folds = 4\n",
    "FM_file_path = '/gpfs/scratch/by2026/quantitativeRehabilitation/stroke_impairment.csv'\n",
    "for i in range(1,5):\n",
    "    HC_dir=f'/gpfs/scratch/by2026/quantitativeRehabilitation/extracted_logits/0906_all_HC_split{i}_best_err/processed_videos/test'\n",
    "    HAR_dir=f'/gpfs/scratch/by2026/quantitativeRehabilitation/extracted_logits/0906_all_HC_split{i}_best_err/processed_videos/test_stroke'\n",
    "    \n",
    "    HC_df_fold,HAR_df_fold =get_COBRA(HC_dir,HAR_dir)\n",
    "    \n",
    "    if HC_df is None:\n",
    "        HC_df = HC_df_fold\n",
    "    else:\n",
    "        HC_df = pd.concat([HC_df,HC_df_fold],ignore_index=True)\n",
    "    \n",
    "    if HAR_df is None:\n",
    "        HAR_df = HAR_df_fold\n",
    "    else:\n",
    "        HAR_df = pd.concat([HAR_df,HAR_df_fold],ignore_index=True)\n",
    "        \n",
    "    HC_blurred_dir=f'/gpfs/scratch/by2026/quantitativeRehabilitation/extracted_logits/0906_all_HC_split{i}_best_err/processed_videos/test_blurry_healthy'\n",
    "    HAR_blurred_dir=f'/gpfs/scratch/by2026/quantitativeRehabilitation/extracted_logits/0906_all_HC_split{i}_best_err/processed_videos/test_blurry'\n",
    "    HC_df_fold,HAR_df_fold =get_COBRA(HC_blurred_dir,HAR_blurred_dir)\n",
    "    \n",
    "    if HC_blurred_df is None:\n",
    "        HC_blurred_df = HC_df_fold\n",
    "    else:\n",
    "        HC_blurred_df = pd.concat([HC_blurred_df,HC_df_fold],ignore_index=True)\n",
    "    \n",
    "    if HAR_blurred_df is None:\n",
    "        HAR_blurred_df = HAR_df_fold\n",
    "    else:\n",
    "        HAR_blurred_df = pd.concat([HAR_blurred_df,HAR_df_fold],ignore_index=True)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_df.to_csv('HC_df.csv',index=False)\n",
    "HAR_df.to_csv('HAR_df.csv',index=False)\n",
    "\n",
    "HC_blurred_df.to_csv('HC_blurred_df.csv',index=False)\n",
    "HAR_blurred_df.to_csv('HAR_blurred_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
